# LLM Configuration
POLICY_EVAL_MODEL=anthropic/claude-sonnet-4-20250514
POLICY_EVAL_TEMPERATURE=0.0

# API Keys (LiteLLM uses standard env vars)
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...

# Optional settings
POLICY_EVAL_MAX_RETRIES=3
POLICY_EVAL_RETRY_WAIT=2

# Confidence thresholds for routing
POLICY_EVAL_CONFIDENCE_HIGH=0.8   # Above this = high confidence (no review needed)
POLICY_EVAL_CONFIDENCE_LOW=0.5    # Below this = low confidence (needs review)

# Phoenix Observability (optional)
# Start Phoenix with: docker-compose up -d phoenix
# Then set PHOENIX_ENABLED=true to enable tracing
# PHOENIX_ENABLED=true
# PHOENIX_COLLECTOR_ENDPOINT=http://localhost:6007
# PHOENIX_PROJECT_NAME=policyflow
